{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection\n",
    "Description\n",
    "This dataset was originally created by Yousef Ghanem. To see the current project, which may have been updated since this version, please go here: https://universe.roboflow.com/yousef-ghanem-jzj4y/brain-tumor-detection-fpf1f.\n",
    "\n",
    "This dataset is part of RF100, an Intel-sponsored initiative to create a new object detection benchmark for model generalizability.\n",
    "\n",
    "Access the RF100 Github repo: https://github.com/roboflow-ai/roboflow-100-benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/brain-tumor-detection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go to project root folder\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 08:25:38.459395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742113538.468796   95271 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742113538.471274   95271 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742113538.480719   95271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742113538.480737   95271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742113538.480739   95271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742113538.480740   95271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-16 08:25:38.486009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], '2.19.0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.config.list_physical_devices('GPU'), tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload dotenv \n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# auto reload libs\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.visualization_funcs import plot_random_images_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/-Brain-Tumor-Detection-2/train/\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "# https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    print(cfg.DATASET_DIRS.TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/train/', 'VALIDATION_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/valid', 'TEST_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/test'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.DATASET_DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET_DIRS = Path(cfg.DATASET.DATASET_DIR)\n",
    "TRAIN_DIR = Path(cfg.DATASET_DIRS.TRAIN_DIR)\n",
    "TEST_DIR = Path(cfg.DATASET_DIRS.TEST_DIR)\n",
    "\n",
    "MODEL_CHECKPOINT = Path(cfg.OUTPUTS.CHECKPOINT_PATH)\n",
    "\n",
    "IMG_SIZE = cfg.TRAIN.IMG_SIZE\n",
    "BATCH_SIZE = cfg.TRAIN.BATCH_SIZE\n",
    "\n",
    "CLASS_NAME = [\n",
    "    'label0',\n",
    "    'label1',\n",
    "    'label2'\n",
    "]\n",
    "class_map = {v: k for k, v in enumerate(CLASS_NAME)}\n",
    "class_map[CLASS_NAME[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN_DIR.exists():\n",
    "    from roboflow import Roboflow\n",
    "    rf = Roboflow()\n",
    "    # https://universe.roboflow.com/roboflow-100/brain-tumor-m2pbp/dataset/2/images?split=test\n",
    "    project = rf.workspace(\"roboflow-100\").project(\"brain-tumor-m2pbp\")\n",
    "    version = project.version(2)\n",
    "    dataset = version.download(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742113546.728785   95271 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7260 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from src.data_handler.annotation_processor import AnnotationProcessor\n",
    "from src.data_handler.data_loader import DataLoader\n",
    "from src.data_handler.preprocessor import Preprocessor\n",
    "_class_map = {v: k for k, v in enumerate(CLASS_NAME)}\n",
    "prepare_test_dataset = AnnotationProcessor(annotation_file= str(TEST_DIR/'_annotations.csv'))\n",
    "test_image_paths, test_class_ids, test_bboxes  = prepare_test_dataset.process_annotations(image_dir=TEST_DIR, class_id_map=_class_map)\n",
    "test_dl = DataLoader(test_image_paths, test_class_ids, test_bboxes).load_val_dataset()\n",
    "test_ds = Preprocessor(test_dl).preprocess()\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# model = keras.models.load_model(str(MODEL_CHECKPOINT/'chpt_49.keras'))\n",
    "# model = keras.models.load_model('output/checkpoints/ckpt_49.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/code/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 218 variables whereas the saved optimizer has 434 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742113686.941964   95530 service.cc:152] XLA service 0x7770b808bf70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742113686.941982   95530 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-03-16 08:28:07.038814: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742113687.703687   95530 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 5/31\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 40ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742113689.825803   95530 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 184ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.89860874, 0.72601676, 0.9379034 ],\n",
       "        [0.280414  , 0.6880886 , 0.6536545 ],\n",
       "        [0.9940362 , 0.7807087 , 0.9924979 ],\n",
       "        ...,\n",
       "        [0.94847995, 0.6151853 , 0.8396786 ],\n",
       "        [0.8802551 , 0.66000146, 0.80798393],\n",
       "        [0.9801492 , 0.8517702 , 0.9924575 ]], dtype=float32),\n",
       " array([[[0.23847501, 0.15602894, 0.7497942 , 0.97365856],\n",
       "         [0.23101969, 0.6446964 , 0.8395523 , 0.9782326 ],\n",
       "         [0.09746745, 0.5666144 , 0.6985348 , 0.94507325]],\n",
       " \n",
       "        [[0.31629896, 0.10791071, 0.8833301 , 0.6657304 ],\n",
       "         [0.35961854, 0.1489991 , 0.9143051 , 0.59768575],\n",
       "         [0.27483326, 0.15443334, 0.8167001 , 0.62916225]],\n",
       " \n",
       "        [[0.2605072 , 0.06173887, 0.5683742 , 0.99473315],\n",
       "         [0.19748934, 0.79036164, 0.8984598 , 0.9979494 ],\n",
       "         [0.02487221, 0.8128542 , 0.7176682 , 0.9916182 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.05268292, 0.10238665, 0.3971132 , 0.58747256],\n",
       "         [0.01898773, 0.12334145, 0.4721198 , 0.70663345],\n",
       "         [0.04234122, 0.13355583, 0.26450264, 0.5538475 ]],\n",
       " \n",
       "        [[0.1540546 , 0.1060504 , 0.6773278 , 0.36832294],\n",
       "         [0.13558285, 0.05110928, 0.8303314 , 0.4511104 ],\n",
       "         [0.0997908 , 0.05767312, 0.5937336 , 0.39023104]],\n",
       " \n",
       "        [[0.33561295, 0.09429885, 0.7632557 , 0.93731785],\n",
       "         [0.18254533, 0.4254108 , 0.861283  , 0.9556893 ],\n",
       "         [0.05416096, 0.36056122, 0.8155857 , 0.927899  ]]], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "model_uri = 'runs:/62c418bd0b544c06af833620b6b88e8a/model'\n",
    "model_uri2 = 'runs:/b846a212193641caa4a3d900f2f5dafa/my_model'\n",
    "loaded_model = mlflow.tensorflow.load_model(model_uri2)\n",
    "\n",
    "loaded_model.predict(test_ds)\n",
    "\n",
    "# Verify the model with the provided input data using the logged dependencies.\n",
    "# For more details, refer to:\n",
    "# https://mlflow.org/docs/latest/models.html#validate-models-before-deployment\n",
    "# mlflow.models.predict(\n",
    "#     model_uri=model_uri,\n",
    "#     input_data=input_data,\n",
    "#     env_manager=\"uv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, return_dict=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_bbx = []\n",
    "for bbx in test_bboxes:\n",
    "   unnorm_bbx.append(bbx*IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def plot_random_images_bbox(*,  random_samples:np.ndarray, image_paths:np.ndarray, class_ids:np.ndarray, bboxes:np.ndarray, class_map:dict) -> None:\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "  print(f\"Random samples: {random_samples}\")\n",
    "  class_map_invert = {v: k for k, v in class_map.items()}\n",
    "  \n",
    "  for i, idx in enumerate(random_samples):\n",
    "    ax = fig.add_subplot(3, 3, i+1)\n",
    "    image = image_paths[idx]\n",
    "    image = cv2.imread(image)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Create title from class IDs\n",
    "    title_labels = [class_map_invert[int(cls_id)] for cls_id in class_ids[idx]]\n",
    "    title = \", \".join(title_labels)\n",
    "    ax.set_title(title)\n",
    "    ax.imshow(image) #display image before bounding box\n",
    "\n",
    "    # Draw bounding boxes with different colors\n",
    "    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0,255,255), (255,0,255)] # Example colors\n",
    "    for j, (xmin, ymin, xmax, ymax) in enumerate(bboxes[idx]):\n",
    "        color = colors[j % len(colors)] # Cycle through colors\n",
    "        cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), color, 1)\n",
    "    ax.imshow(image) #display image with bounding box.\n",
    "\n",
    "  plt.tight_layout() #prevents overlapping subplots\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = random.sample(range(len(test_images)), 9)\n",
    "plot_random_images_bbox(random_samples=random_samples,\n",
    "                        image_paths=test_images, \n",
    "                        class_ids=test_class_ids, \n",
    "                        bboxes=unnorm_bbx,\n",
    "                        class_map=class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls_id, pred_bbx = model.predict(test_ds)\n",
    "print(pred_cls_id.shape, pred_bbx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_pred_bbx = []\n",
    "for bbx in pred_bbx:\n",
    "   unnorm_pred_bbx.append(bbx*IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls_id = (pred_cls_id>0.5).astype(int)\n",
    "pred_cls_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cls = [np.where(row==1)[0].tolist() for row in pred_cls_id]\n",
    "pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in random_samples:\n",
    "   print([cls_id for cls_id in pred_cls[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_images_bbox(random_samples=random_samples,\n",
    "                        image_paths=test_images, \n",
    "                        class_ids=pred_cls, \n",
    "                        bboxes=unnorm_pred_bbx,\n",
    "                        class_map=class_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm_bbx, pred_bbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses.iou_loss import iou_metric\n",
    "for y_tbbx, y_prdbbx in zip(unnorm_bbx, unnorm_pred_bbx):\n",
    "    print(iou_metric(y_true=y_tbbx, y_pred=y_prdbbx)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
