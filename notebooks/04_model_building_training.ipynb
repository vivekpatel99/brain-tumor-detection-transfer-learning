{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection\n",
    "## Resnet101 - Classifier + Regressor\n",
    "Description\n",
    "This dataset was originally created by Yousef Ghanem. To see the current project, which may have been updated since this version, please go here: https://universe.roboflow.com/yousef-ghanem-jzj4y/brain-tumor-detection-fpf1f.\n",
    "\n",
    "This dataset is part of RF100, an Intel-sponsored initiative to create a new object detection benchmark for model generalizability.\n",
    "\n",
    "Access the RF100 Github repo: https://github.com/roboflow-ai/roboflow-100-benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/brain-tumor-detection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go to project root folder\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 07:56:03.666137: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742802963.674251   48909 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742802963.676712   48909 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742802963.686598   48909 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742802963.686613   48909 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742802963.686615   48909 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742802963.686616   48909 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 07:56:03.690004: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed precision training\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], '2.19.0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_gpu = tf.config.list_physical_devices('GPU')\n",
    "if not found_gpu:\n",
    "    raise Exception(\"No GPU found\")\n",
    "found_gpu, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_handler.data_loader import DataLoader\n",
    "from src.data_handler.annotation_processor import AnnotationProcessor\n",
    "from src.data_handler.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload dotenv \n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# auto reload libs\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/-Brain-Tumor-Detection-2/train/\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "# https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    print(cfg.DATASET_DIRS.TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/train/', 'VALIDATION_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/valid', 'TEST_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/test'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.DATASET_DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRS = Path(cfg.DATASET.DATASET_DIR)\n",
    "TRAIN_DIR = Path(cfg.DATASET_DIRS.TRAIN_DIR)\n",
    "VALIDATION_DIR = Path(cfg.DATASET_DIRS.VALIDATION_DIR)\n",
    "TEST_DIR = Path(cfg.DATASET_DIRS.TEST_DIR)\n",
    "OUTPUT_DIR = Path(cfg.OUTPUTS.OUTPUT_DIR)\n",
    "\n",
    "IMG_SIZE = cfg.TRAIN.IMG_SIZE\n",
    "BATCH_SIZE = cfg.TRAIN.BATCH_SIZE\n",
    "LOG_DIR = cfg.OUTPUTS.LOG_DIR\n",
    "CHECK_POINT_DIR = Path(cfg.OUTPUTS.CHECKPOINT_PATH)\n",
    "CLASS_NAME = [\n",
    "    'label0',\n",
    "    'label1',\n",
    "    'label2'\n",
    "]\n",
    "class_map = {k: v for k, v in enumerate(CLASS_NAME)}\n",
    "\n",
    "NUM_EPOCHS = cfg.TRAIN.NUM_EPOCHS\n",
    "LEARNING_RATE = cfg.TRAIN.LEARNING_RATE\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN_DIR.exists():\n",
    "    from roboflow import Roboflow\n",
    "    rf = Roboflow()\n",
    "    project = rf.workspace(\"yousef-ghanem-jzj4y\").project(\"brain-tumor-detection-fpf1f\")\n",
    "    version = project.version(2)\n",
    "    dataset = version.download(\"tensorflow\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 6851)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_train_dataset = AnnotationProcessor(annotation_file= str(TRAIN_DIR/'_annotations.csv'))\n",
    "_class_map = {v: k for k, v in enumerate(CLASS_NAME)}\n",
    "train_images, train_class_ids, train_bboxes  = prepare_train_dataset.process_annotations(image_dir=TRAIN_DIR, class_id_map=_class_map)\n",
    "\n",
    "len(train_images), len(train_class_ids), len(train_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68345324, 0.54545455, 0.95683453, 0.76515152],\n",
       "       [0.42446043, 0.48484848, 0.99280576, 0.96969697],\n",
       "       [0.46043165, 0.53030303, 0.99280576, 0.78030303]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bboxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1],\n",
       " [2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [0, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1, 2],\n",
       " [0, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [0, 1],\n",
       " [1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [1],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " [0, 1, 2],\n",
       " [1],\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742802977.231147   48909 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7397 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_images, train_class_ids, train_bboxes)\n",
    "train_ds = train_dl.load_train_dataset()\n",
    "train_ds = Preprocessor(train_ds).preprocess()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 240, 240, 3) (32, 3) (32, 3, 4)\n",
      "tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n",
      "-123.7 145.0\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 0.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[0. 1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 07:56:25.306497: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in train_ds.take(1):\n",
    "    image, (cls, bbx) = batch\n",
    "    print(image.shape, cls.shape, bbx.shape)\n",
    "    print(cls[5])\n",
    "    print(image[1].numpy().min(), image[1].numpy().max())\n",
    "    for c in cls:\n",
    "        print(c.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation datasets setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1963, 1963, 1963)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_valid_dataset = AnnotationProcessor(annotation_file= str(VALIDATION_DIR/'_annotations.csv'))\n",
    "\n",
    "valid_image_paths, valid_class_ids, valid_bboxes  = prepare_valid_dataset.process_annotations(image_dir=VALIDATION_DIR, class_id_map=_class_map)\n",
    "len(valid_image_paths), len(valid_class_ids), len(valid_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_image_paths, valid_class_ids, valid_bboxes).load_val_dataset()\n",
    "valid_ds = Preprocessor(valid_dl).preprocess()\n",
    "valid_ds = valid_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 240, 240, 3) (32, 3) (32, 3, 4)\n",
      "-123.68 138.49847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 07:56:26.487140: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in valid_ds.take(1):\n",
    "    image, (cls, bbx) = batch\n",
    "    print(image.shape, cls.shape, bbx.shape)\n",
    "    print(image[1].numpy().min(), image[1].numpy().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_class_ids = train_dl.multi_hot_class_ids\n",
    "padded_class_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.38140417, 0.01547219, 0.40767771]),\n",
       " array([0.61859584, 0.9845278 , 0.5923223 ], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.losses import binary_weighted_loss as _loss\n",
    "\n",
    "positive_weights, negative_weights = _loss.compute_class_weights(padded_class_ids)\n",
    "positive_weights, negative_weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ResNet50 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses import iou_loss\n",
    "CLS_METRICS = [\n",
    "    tf.keras.metrics.AUC(name='AUC', multi_label=True), \n",
    "    tf.keras.metrics.F1Score(name='f1_score',average='weighted')]\n",
    "\n",
    "\n",
    "REG_METRICS = [\n",
    "    iou_loss.iou_metric,\n",
    "    tf.keras.metrics.MeanSquaredError(name='mse'),\n",
    "    tf.keras.metrics.MeanAbsoluteError(name='mae'),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define  Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, TensorSpec\n",
    "# 1. Input Schema\n",
    "# -----------------\n",
    "# Your input is a batch of images with shape (32, 240, 240, 3)\n",
    "# We use -1 to indicate that the batch size can vary.\n",
    "input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, IMG_SIZE, IMG_SIZE, 3), \"image\")])\n",
    "\n",
    "# 2. Output Schema - Multilabel binary classification head\n",
    "# ------------------\n",
    "# Your model outputs a list of two arrays. We need to define a schema for each.\n",
    "# Array 1: Shape (1, 3)\n",
    "output_schema_array1 = TensorSpec(np.dtype(np.float32), (-1, 3), \"classification\")\n",
    "\n",
    "# Array 2: Shape (1, 3, 4) - 3 Bounding boxes per classification \n",
    "output_schema_array2 = TensorSpec(np.dtype(np.float32), (-1, 3, 4), \"bounding_box\")\n",
    "\n",
    "# Create a schema for the list of outputs\n",
    "output_schema = Schema([output_schema_array1, output_schema_array2])\n",
    "\n",
    "# 3. Model Signature\n",
    "# --------------------\n",
    "# Combine the input and output schemas into a ModelSignature\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "# to_monitor = 'val_classification_AUC'\n",
    "# mode = 'max'\n",
    "to_monitor = 'val_bounding_box_mse'\n",
    "mode = 'min'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, \n",
    "                                            patience=5, \n",
    "                                            monitor=to_monitor,\n",
    "                                            mode=mode,\n",
    "                                            min_lr=1e-7,\n",
    "                                            verbose=1),\n",
    "\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(str(CHECK_POINT_DIR), \"detector_ckpt_{epoch}.keras\") ,\n",
    "                                        save_weights_only=False,\n",
    "                                        save_best_only=True,\n",
    "                                        monitor=to_monitor,\n",
    "                                        mode=mode,\n",
    "                                        verbose=1),\n",
    "                                        \n",
    "    tf.keras.callbacks.EarlyStopping(monitor=to_monitor, \n",
    "                                    patience=10,\n",
    "                                    mode=mode, \n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1),\n",
    "\n",
    "    ]\n",
    "\n",
    "mlflow_exp = mlflow.set_experiment(\"/brain-tumor-resnet101-phase-training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, alpha=0.7, beta=0.3):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        cls_loss = _loss.set_binary_crossentropy_weighted_loss(\n",
    "            positive_weights, negative_weights)(y_true[0], y_pred[0])\n",
    "        box_loss = iou_loss.iou_loss(y_true[1], y_pred[1])\n",
    "        return self.alpha * cls_loss + self.beta * box_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Validate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Train feature extractor with classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/24 07:56:28 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.7.4 <= tensorflow <= 2.18.0, but the installed version is 2.19.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "run = mlflow.start_run() \n",
    "mlflow.tensorflow.autolog(log_models=True, \n",
    "                        log_datasets=False, \n",
    "                        log_input_examples=True,\n",
    "                        log_model_signatures=True,\n",
    "                        keras_model_kwargs={\"save_format\": \"keras\"},\n",
    "                        checkpoint_monitor=to_monitor, \n",
    "                        checkpoint_mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.resnet101V2 import final_model\n",
    "\n",
    "model = final_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=NUM_CLASSES)\n",
    "\n",
    "# Freeze regression branch and feature extractor\n",
    "for layer in model.layers:\n",
    "    if 'bounding_box' not in layer.name:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only enable classification training\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(learning_rate=3e-4),\n",
    "    loss={'classification': _loss.set_binary_crossentropy_weighted_loss(positive_weights, negative_weights),\n",
    "          'bounding_box':  iou_loss.iou_loss},\n",
    "    metrics={'classification': CLS_METRICS, 'bounding_box': REG_METRICS},\n",
    "    loss_weights={'classification': 1.0, 'bounding_box': 0.0}\n",
    "    )\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1742803034.059453   49196 service.cc:152] XLA service 0x7387e8003310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742803034.059484   49196 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2025-03-24 07:57:14.913609: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742803041.297881   49196 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1742803072.565411   49196 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - bounding_box_iou_metric: 0.0026 - bounding_box_loss: 0.9974 - bounding_box_mae: 0.8207 - bounding_box_mse: 1.2125 - classification_AUC: 0.6552 - classification_f1_score: 0.5125 - classification_loss: 0.6330 - loss: 0.6817\n",
      "Epoch 1: saving model to output/checkpoints/phase1.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 309ms/step - bounding_box_iou_metric: 0.0026 - bounding_box_loss: 0.9974 - bounding_box_mae: 0.8204 - bounding_box_mse: 1.2119 - classification_AUC: 0.6554 - classification_f1_score: 0.5126 - classification_loss: 0.6329 - loss: 0.6815 - val_bounding_box_iou_metric: 0.0025 - val_bounding_box_loss: 0.9975 - val_bounding_box_mae: 1.0915 - val_bounding_box_mse: 3.0550 - val_classification_AUC: 0.7779 - val_classification_f1_score: 0.3342 - val_classification_loss: 0.6862 - val_loss: 0.7095\n",
      "Epoch 2/30\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - bounding_box_iou_metric: 0.0026 - bounding_box_loss: 0.9974 - bounding_box_mae: 0.7384 - bounding_box_mse: 1.0928 - classification_AUC: 0.7819 - classification_f1_score: 0.5473 - classification_loss: 0.5323 - loss: 0.5553\n",
      "Epoch 2: saving model to output/checkpoints/phase1.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 114ms/step - bounding_box_iou_metric: 0.0026 - bounding_box_loss: 0.9974 - bounding_box_mae: 0.7384 - bounding_box_mse: 1.0927 - classification_AUC: 0.7819 - classification_f1_score: 0.5473 - classification_loss: 0.5322 - loss: 0.5553 - val_bounding_box_iou_metric: 0.0025 - val_bounding_box_loss: 0.9976 - val_bounding_box_mae: 0.7982 - val_bounding_box_mse: 1.3213 - val_classification_AUC: 0.7946 - val_classification_f1_score: 0.4933 - val_classification_loss: 0.5621 - val_loss: 0.5753\n",
      "Epoch 3/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - bounding_box_iou_metric: 0.0022 - bounding_box_loss: 0.9978 - bounding_box_mae: 0.7929 - bounding_box_mse: 1.2315 - classification_AUC: 0.8455 - classification_f1_score: 0.5673 - classification_loss: 0.4529 - loss: 0.4678\n",
      "Epoch 3: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 104ms/step - bounding_box_iou_metric: 0.0022 - bounding_box_loss: 0.9978 - bounding_box_mae: 0.7929 - bounding_box_mse: 1.2317 - classification_AUC: 0.8455 - classification_f1_score: 0.5674 - classification_loss: 0.4529 - loss: 0.4678 - val_bounding_box_iou_metric: 0.0043 - val_bounding_box_loss: 0.9956 - val_bounding_box_mae: 0.9340 - val_bounding_box_mse: 1.6453 - val_classification_AUC: 0.8033 - val_classification_f1_score: 0.3972 - val_classification_loss: 0.6019 - val_loss: 0.6112\n",
      "Epoch 4/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - bounding_box_iou_metric: 0.0024 - bounding_box_loss: 0.9976 - bounding_box_mae: 0.8234 - bounding_box_mse: 1.3254 - classification_AUC: 0.8818 - classification_f1_score: 0.5983 - classification_loss: 0.3784 - loss: 0.3896\n",
      "Epoch 4: saving model to output/checkpoints/phase1.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 114ms/step - bounding_box_iou_metric: 0.0024 - bounding_box_loss: 0.9976 - bounding_box_mae: 0.8234 - bounding_box_mse: 1.3257 - classification_AUC: 0.8818 - classification_f1_score: 0.5983 - classification_loss: 0.3784 - loss: 0.3896 - val_bounding_box_iou_metric: 0.0013 - val_bounding_box_loss: 0.9987 - val_bounding_box_mae: 0.7470 - val_bounding_box_mse: 1.0330 - val_classification_AUC: 0.8290 - val_classification_f1_score: 0.5789 - val_classification_loss: 0.5301 - val_loss: 0.5359\n",
      "Epoch 5/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - bounding_box_iou_metric: 0.0021 - bounding_box_loss: 0.9979 - bounding_box_mae: 0.8671 - bounding_box_mse: 1.4454 - classification_AUC: 0.9047 - classification_f1_score: 0.6107 - classification_loss: 0.3128 - loss: 0.3218\n",
      "Epoch 5: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 110ms/step - bounding_box_iou_metric: 0.0021 - bounding_box_loss: 0.9979 - bounding_box_mae: 0.8671 - bounding_box_mse: 1.4454 - classification_AUC: 0.9047 - classification_f1_score: 0.6107 - classification_loss: 0.3129 - loss: 0.3219 - val_bounding_box_iou_metric: 0.0015 - val_bounding_box_loss: 0.9985 - val_bounding_box_mae: 0.8659 - val_bounding_box_mse: 1.4705 - val_classification_AUC: 0.8570 - val_classification_f1_score: 0.5664 - val_classification_loss: 0.5220 - val_loss: 0.5298\n",
      "Epoch 6/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - bounding_box_iou_metric: 0.0024 - bounding_box_loss: 0.9976 - bounding_box_mae: 0.8674 - bounding_box_mse: 1.4489 - classification_AUC: 0.9282 - classification_f1_score: 0.6321 - classification_loss: 0.2513 - loss: 0.2589\n",
      "Epoch 6: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 118ms/step - bounding_box_iou_metric: 0.0024 - bounding_box_loss: 0.9976 - bounding_box_mae: 0.8674 - bounding_box_mse: 1.4488 - classification_AUC: 0.9282 - classification_f1_score: 0.6321 - classification_loss: 0.2514 - loss: 0.2590 - val_bounding_box_iou_metric: 0.0015 - val_bounding_box_loss: 0.9985 - val_bounding_box_mae: 0.7979 - val_bounding_box_mse: 1.2088 - val_classification_AUC: 0.8708 - val_classification_f1_score: 0.5780 - val_classification_loss: 0.4807 - val_loss: 0.4867\n",
      "Epoch 7/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - bounding_box_iou_metric: 0.0030 - bounding_box_loss: 0.9970 - bounding_box_mae: 0.7957 - bounding_box_mse: 1.1875 - classification_AUC: 0.9277 - classification_f1_score: 0.6098 - classification_loss: 0.3009 - loss: 0.3075\n",
      "Epoch 7: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 115ms/step - bounding_box_iou_metric: 0.0030 - bounding_box_loss: 0.9970 - bounding_box_mae: 0.7959 - bounding_box_mse: 1.1882 - classification_AUC: 0.9278 - classification_f1_score: 0.6100 - classification_loss: 0.3006 - loss: 0.3072 - val_bounding_box_iou_metric: 0.0018 - val_bounding_box_loss: 0.9982 - val_bounding_box_mae: 0.8253 - val_bounding_box_mse: 1.2714 - val_classification_AUC: 0.8903 - val_classification_f1_score: 0.5897 - val_classification_loss: 0.5013 - val_loss: 0.5084\n",
      "Epoch 8/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - bounding_box_iou_metric: 0.0025 - bounding_box_loss: 0.9975 - bounding_box_mae: 0.8675 - bounding_box_mse: 1.4043 - classification_AUC: 0.9646 - classification_f1_score: 0.6573 - classification_loss: 0.1733 - loss: 0.1796\n",
      "Epoch 8: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 111ms/step - bounding_box_iou_metric: 0.0025 - bounding_box_loss: 0.9975 - bounding_box_mae: 0.8674 - bounding_box_mse: 1.4040 - classification_AUC: 0.9646 - classification_f1_score: 0.6572 - classification_loss: 0.1734 - loss: 0.1797 - val_bounding_box_iou_metric: 0.0021 - val_bounding_box_loss: 0.9979 - val_bounding_box_mae: 0.8073 - val_bounding_box_mse: 1.2152 - val_classification_AUC: 0.9113 - val_classification_f1_score: 0.5887 - val_classification_loss: 0.4670 - val_loss: 0.4753\n",
      "Epoch 9/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - bounding_box_iou_metric: 0.0023 - bounding_box_loss: 0.9977 - bounding_box_mae: 0.8807 - bounding_box_mse: 1.4463 - classification_AUC: 0.9754 - classification_f1_score: 0.6546 - classification_loss: 0.1485 - loss: 0.1545\n",
      "Epoch 9: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 108ms/step - bounding_box_iou_metric: 0.0023 - bounding_box_loss: 0.9977 - bounding_box_mae: 0.8806 - bounding_box_mse: 1.4462 - classification_AUC: 0.9754 - classification_f1_score: 0.6547 - classification_loss: 0.1485 - loss: 0.1544 - val_bounding_box_iou_metric: 0.0021 - val_bounding_box_loss: 0.9979 - val_bounding_box_mae: 0.7958 - val_bounding_box_mse: 1.1618 - val_classification_AUC: 0.8952 - val_classification_f1_score: 0.5908 - val_classification_loss: 0.5291 - val_loss: 0.5338\n",
      "Epoch 10/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - bounding_box_iou_metric: 0.0020 - bounding_box_loss: 0.9980 - bounding_box_mae: 0.8449 - bounding_box_mse: 1.3618 - classification_AUC: 0.9566 - classification_f1_score: 0.6488 - classification_loss: 0.1614 - loss: 0.1669\n",
      "Epoch 10: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 105ms/step - bounding_box_iou_metric: 0.0020 - bounding_box_loss: 0.9980 - bounding_box_mae: 0.8450 - bounding_box_mse: 1.3617 - classification_AUC: 0.9567 - classification_f1_score: 0.6488 - classification_loss: 0.1613 - loss: 0.1668 - val_bounding_box_iou_metric: 0.0019 - val_bounding_box_loss: 0.9981 - val_bounding_box_mae: 0.8004 - val_bounding_box_mse: 1.1720 - val_classification_AUC: 0.9059 - val_classification_f1_score: 0.6138 - val_classification_loss: 0.4745 - val_loss: 0.4814\n",
      "Epoch 11/30\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - bounding_box_iou_metric: 0.0022 - bounding_box_loss: 0.9978 - bounding_box_mae: 0.8696 - bounding_box_mse: 1.3880 - classification_AUC: 0.9821 - classification_f1_score: 0.6623 - classification_loss: 0.1164 - loss: 0.1217\n",
      "Epoch 11: saving model to output/checkpoints/phase1.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 108ms/step - bounding_box_iou_metric: 0.0022 - bounding_box_loss: 0.9978 - bounding_box_mae: 0.8697 - bounding_box_mse: 1.3883 - classification_AUC: 0.9821 - classification_f1_score: 0.6624 - classification_loss: 0.1164 - loss: 0.1217 - val_bounding_box_iou_metric: 0.0021 - val_bounding_box_loss: 0.9978 - val_bounding_box_mae: 0.8353 - val_bounding_box_mse: 1.2686 - val_classification_AUC: 0.9042 - val_classification_f1_score: 0.6277 - val_classification_loss: 0.5814 - val_loss: 0.5899\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/24 08:04:21 WARNING mlflow.models.signature: Failed to infer schema for outputs. Setting schema to `Schema([ColSpec(type=AnyType())]` as default. To see the full traceback, set logging level to DEBUG.\n",
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n",
      "2025/03/24 08:04:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpoz6yczjz/model, flavor: tensorflow). Fall back to return ['tensorflow==2.19.0', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/03/24 08:04:36 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "to_monitor = 'val_classification_loss'\n",
    "mode = 'min'\n",
    "phase1_epoch = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=phase1_epoch,\n",
    "    validation_data=valid_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[ \n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(str(CHECK_POINT_DIR), \"phase1.weights.h5\") ,\n",
    "                                        save_weights_only=True,\n",
    "                                        save_best_only=False,\n",
    "                                        monitor=to_monitor,\n",
    "                                        mode=mode,\n",
    "                                        verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=to_monitor, \n",
    "                                    patience=3,\n",
    "                                    mode=mode, \n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Freeze classification head and train bounding box head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch trainable components\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False  # Freeze all first\n",
    "    if 'bounding_box' in layer.name:\n",
    "        layer.trainable = True\n",
    "    if 'conv5_block3' in layer.name:  # Unfreeze deeper ResNet layers\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW(1e-4),\n",
    "    loss={'classification': _loss.set_binary_crossentropy_weighted_loss(positive_weights, negative_weights),\n",
    "          'bounding_box':  iou_loss.iou_loss},\n",
    "    metrics={'classification': CLS_METRICS, 'bounding_box': REG_METRICS},\n",
    "    loss_weights={'classification': 0.0, 'bounding_box': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - bounding_box_iou_metric: 0.3955 - bounding_box_loss: 0.6045 - bounding_box_mae: 0.2774 - bounding_box_mse: 0.1902 - classification_AUC: 0.9328 - classification_f1_score: 0.5638 - classification_loss: 0.5354 - loss: 0.6045\n",
      "Epoch 70: saving model to output/checkpoints/phase2.weights.h5\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 105ms/step - bounding_box_iou_metric: 0.3955 - bounding_box_loss: 0.6045 - bounding_box_mae: 0.2774 - bounding_box_mse: 0.1902 - classification_AUC: 0.9328 - classification_f1_score: 0.5638 - classification_loss: 0.5354 - loss: 0.6045 - val_bounding_box_iou_metric: 0.2620 - val_bounding_box_loss: 0.7384 - val_bounding_box_mae: 0.2890 - val_bounding_box_mse: 0.1930 - val_classification_AUC: 0.8818 - val_classification_f1_score: 0.5485 - val_classification_loss: 0.5880 - val_loss: 0.7381 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 70.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/24 08:23:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='epochs' was already logged with value='30' for run ID='f0c78cc579984d95a3fb284db4a43dc0'. Attempted logging new value '70'.\n"
     ]
    }
   ],
   "source": [
    "# Set the number of epochs for fine-tuning\n",
    "to_monitor = 'val_bounding_box_iou_metric'\n",
    "mode = 'max'\n",
    "phase2_epoch = phase1_epoch + 40 \n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=phase2_epoch,\n",
    "    initial_epoch=history.epoch[-1],  # Start from the last epoch of initial training\n",
    "    validation_data=valid_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[ \n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, \n",
    "                                            patience=5, \n",
    "                                            monitor=to_monitor,\n",
    "                                            mode=mode,\n",
    "                                            min_lr=1e-7,\n",
    "                                            verbose=1),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(str(CHECK_POINT_DIR), \"phase2.weights.h5\") ,\n",
    "                                        save_weights_only=True,\n",
    "                                        save_best_only=False,\n",
    "                                        monitor=to_monitor,\n",
    "                                        mode=mode,\n",
    "                                        verbose=1),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=to_monitor, \n",
    "                                    patience=5,\n",
    "                                    mode=mode, \n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Fine-tune entire model with reduced learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all layers except first 150\n",
    "for layer in model.layers[:150]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[150:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.AdamW( learning_rate=1e-5, \n",
    "    clipnorm=1.0  # Essential for stable training\n",
    "    ),\n",
    "    loss={'classification': _loss.set_binary_crossentropy_weighted_loss(positive_weights, negative_weights),\n",
    "          'bounding_box':  iou_loss.iou_loss},\n",
    "    metrics={'classification': CLS_METRICS, 'bounding_box': REG_METRICS},\n",
    "    # Train with 0 weight for classification\n",
    "    loss_weights={'classification': 0.1,  'bounding_box': 0.9 } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - bounding_box_iou_metric: 0.3356 - bounding_box_loss: 0.6644 - bounding_box_mae: 0.2778 - bounding_box_mse: 0.1945 - classification_AUC: 0.9861 - classification_f1_score: 0.6272 - classification_loss: 0.0829 - loss: 0.6132\n",
      "Epoch 70: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 211ms/step - bounding_box_iou_metric: 0.3356 - bounding_box_loss: 0.6644 - bounding_box_mae: 0.2778 - bounding_box_mse: 0.1945 - classification_AUC: 0.9861 - classification_f1_score: 0.6272 - classification_loss: 0.0829 - loss: 0.6132 - val_bounding_box_iou_metric: 0.2634 - val_bounding_box_loss: 0.7366 - val_bounding_box_mae: 0.2893 - val_bounding_box_mse: 0.1970 - val_classification_AUC: 0.9099 - val_classification_f1_score: 0.5888 - val_classification_loss: 0.4350 - val_loss: 0.7134 - learning_rate: 1.0000e-05\n",
      "Epoch 71/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - bounding_box_iou_metric: 0.3449 - bounding_box_loss: 0.6556 - bounding_box_mae: 0.2786 - bounding_box_mse: 0.1952 - classification_AUC: 0.9829 - classification_f1_score: 0.6286 - classification_loss: 0.0927 - loss: 0.6059\n",
      "Epoch 71: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.3449 - bounding_box_loss: 0.6556 - bounding_box_mae: 0.2786 - bounding_box_mse: 0.1952 - classification_AUC: 0.9829 - classification_f1_score: 0.6286 - classification_loss: 0.0927 - loss: 0.6059 - val_bounding_box_iou_metric: 0.2762 - val_bounding_box_loss: 0.7239 - val_bounding_box_mae: 0.2919 - val_bounding_box_mse: 0.2023 - val_classification_AUC: 0.9100 - val_classification_f1_score: 0.5835 - val_classification_loss: 0.4402 - val_loss: 0.7020 - learning_rate: 1.0000e-05\n",
      "Epoch 72/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.3513 - bounding_box_loss: 0.6489 - bounding_box_mae: 0.2798 - bounding_box_mse: 0.2006 - classification_AUC: 0.9828 - classification_f1_score: 0.6236 - classification_loss: 0.0852 - loss: 0.5988\n",
      "Epoch 72: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - bounding_box_iou_metric: 0.3513 - bounding_box_loss: 0.6489 - bounding_box_mae: 0.2798 - bounding_box_mse: 0.2005 - classification_AUC: 0.9829 - classification_f1_score: 0.6236 - classification_loss: 0.0852 - loss: 0.5988 - val_bounding_box_iou_metric: 0.2757 - val_bounding_box_loss: 0.7244 - val_bounding_box_mae: 0.2845 - val_bounding_box_mse: 0.1909 - val_classification_AUC: 0.9102 - val_classification_f1_score: 0.5852 - val_classification_loss: 0.4388 - val_loss: 0.7020 - learning_rate: 1.0000e-05\n",
      "Epoch 73/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.3650 - bounding_box_loss: 0.6349 - bounding_box_mae: 0.2767 - bounding_box_mse: 0.1947 - classification_AUC: 0.9859 - classification_f1_score: 0.6328 - classification_loss: 0.0804 - loss: 0.5854\n",
      "Epoch 73: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.3650 - bounding_box_loss: 0.6349 - bounding_box_mae: 0.2767 - bounding_box_mse: 0.1947 - classification_AUC: 0.9859 - classification_f1_score: 0.6327 - classification_loss: 0.0804 - loss: 0.5854 - val_bounding_box_iou_metric: 0.2836 - val_bounding_box_loss: 0.7165 - val_bounding_box_mae: 0.2862 - val_bounding_box_mse: 0.1952 - val_classification_AUC: 0.9090 - val_classification_f1_score: 0.5845 - val_classification_loss: 0.4466 - val_loss: 0.6956 - learning_rate: 1.0000e-05\n",
      "Epoch 74/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.3776 - bounding_box_loss: 0.6230 - bounding_box_mae: 0.2723 - bounding_box_mse: 0.1906 - classification_AUC: 0.9800 - classification_f1_score: 0.6320 - classification_loss: 0.0740 - loss: 0.5738\n",
      "Epoch 74: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.3775 - bounding_box_loss: 0.6230 - bounding_box_mae: 0.2723 - bounding_box_mse: 0.1906 - classification_AUC: 0.9801 - classification_f1_score: 0.6320 - classification_loss: 0.0741 - loss: 0.5738 - val_bounding_box_iou_metric: 0.2848 - val_bounding_box_loss: 0.7151 - val_bounding_box_mae: 0.2877 - val_bounding_box_mse: 0.1988 - val_classification_AUC: 0.9097 - val_classification_f1_score: 0.5837 - val_classification_loss: 0.4414 - val_loss: 0.6937 - learning_rate: 1.0000e-05\n",
      "Epoch 75/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.3823 - bounding_box_loss: 0.6178 - bounding_box_mae: 0.2741 - bounding_box_mse: 0.1968 - classification_AUC: 0.9842 - classification_f1_score: 0.6267 - classification_loss: 0.0856 - loss: 0.5700\n",
      "Epoch 75: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.3823 - bounding_box_loss: 0.6178 - bounding_box_mae: 0.2741 - bounding_box_mse: 0.1968 - classification_AUC: 0.9842 - classification_f1_score: 0.6267 - classification_loss: 0.0856 - loss: 0.5700 - val_bounding_box_iou_metric: 0.2855 - val_bounding_box_loss: 0.7146 - val_bounding_box_mae: 0.2860 - val_bounding_box_mse: 0.1952 - val_classification_AUC: 0.9096 - val_classification_f1_score: 0.5849 - val_classification_loss: 0.4428 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 76/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.3866 - bounding_box_loss: 0.6133 - bounding_box_mae: 0.2727 - bounding_box_mse: 0.1945 - classification_AUC: 0.9844 - classification_f1_score: 0.6274 - classification_loss: 0.0826 - loss: 0.5656\n",
      "Epoch 76: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 68ms/step - bounding_box_iou_metric: 0.3866 - bounding_box_loss: 0.6133 - bounding_box_mae: 0.2726 - bounding_box_mse: 0.1945 - classification_AUC: 0.9844 - classification_f1_score: 0.6275 - classification_loss: 0.0825 - loss: 0.5656 - val_bounding_box_iou_metric: 0.2917 - val_bounding_box_loss: 0.7084 - val_bounding_box_mae: 0.2806 - val_bounding_box_mse: 0.1888 - val_classification_AUC: 0.9090 - val_classification_f1_score: 0.5819 - val_classification_loss: 0.4484 - val_loss: 0.6878 - learning_rate: 1.0000e-05\n",
      "Epoch 77/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.3877 - bounding_box_loss: 0.6126 - bounding_box_mae: 0.2694 - bounding_box_mse: 0.1881 - classification_AUC: 0.9831 - classification_f1_score: 0.6348 - classification_loss: 0.0833 - loss: 0.5649\n",
      "Epoch 77: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.3877 - bounding_box_loss: 0.6126 - bounding_box_mae: 0.2694 - bounding_box_mse: 0.1881 - classification_AUC: 0.9832 - classification_f1_score: 0.6348 - classification_loss: 0.0833 - loss: 0.5648 - val_bounding_box_iou_metric: 0.2924 - val_bounding_box_loss: 0.7077 - val_bounding_box_mae: 0.2833 - val_bounding_box_mse: 0.1939 - val_classification_AUC: 0.9096 - val_classification_f1_score: 0.5856 - val_classification_loss: 0.4434 - val_loss: 0.6865 - learning_rate: 1.0000e-05\n",
      "Epoch 78/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.3988 - bounding_box_loss: 0.6016 - bounding_box_mae: 0.2675 - bounding_box_mse: 0.1892 - classification_AUC: 0.9758 - classification_f1_score: 0.6333 - classification_loss: 0.0826 - loss: 0.5547\n",
      "Epoch 78: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.3988 - bounding_box_loss: 0.6016 - bounding_box_mae: 0.2675 - bounding_box_mse: 0.1892 - classification_AUC: 0.9759 - classification_f1_score: 0.6333 - classification_loss: 0.0826 - loss: 0.5547 - val_bounding_box_iou_metric: 0.2938 - val_bounding_box_loss: 0.7062 - val_bounding_box_mae: 0.2790 - val_bounding_box_mse: 0.1897 - val_classification_AUC: 0.9091 - val_classification_f1_score: 0.5838 - val_classification_loss: 0.4541 - val_loss: 0.6862 - learning_rate: 1.0000e-05\n",
      "Epoch 79/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4021 - bounding_box_loss: 0.5980 - bounding_box_mae: 0.2662 - bounding_box_mse: 0.1903 - classification_AUC: 0.9806 - classification_f1_score: 0.6299 - classification_loss: 0.0817 - loss: 0.5512\n",
      "Epoch 79: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4021 - bounding_box_loss: 0.5980 - bounding_box_mae: 0.2662 - bounding_box_mse: 0.1903 - classification_AUC: 0.9807 - classification_f1_score: 0.6300 - classification_loss: 0.0817 - loss: 0.5512 - val_bounding_box_iou_metric: 0.2973 - val_bounding_box_loss: 0.7028 - val_bounding_box_mae: 0.2792 - val_bounding_box_mse: 0.1902 - val_classification_AUC: 0.9093 - val_classification_f1_score: 0.5863 - val_classification_loss: 0.4525 - val_loss: 0.6826 - learning_rate: 1.0000e-05\n",
      "Epoch 80/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4030 - bounding_box_loss: 0.5975 - bounding_box_mae: 0.2677 - bounding_box_mse: 0.1894 - classification_AUC: 0.9668 - classification_f1_score: 0.6360 - classification_loss: 0.0812 - loss: 0.5505\n",
      "Epoch 80: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4030 - bounding_box_loss: 0.5974 - bounding_box_mae: 0.2677 - bounding_box_mse: 0.1894 - classification_AUC: 0.9670 - classification_f1_score: 0.6359 - classification_loss: 0.0811 - loss: 0.5505 - val_bounding_box_iou_metric: 0.2908 - val_bounding_box_loss: 0.7095 - val_bounding_box_mae: 0.2766 - val_bounding_box_mse: 0.1867 - val_classification_AUC: 0.9090 - val_classification_f1_score: 0.5874 - val_classification_loss: 0.4567 - val_loss: 0.6889 - learning_rate: 1.0000e-05\n",
      "Epoch 81/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4121 - bounding_box_loss: 0.5879 - bounding_box_mae: 0.2659 - bounding_box_mse: 0.1896 - classification_AUC: 0.9844 - classification_f1_score: 0.6399 - classification_loss: 0.0850 - loss: 0.5422\n",
      "Epoch 81: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4121 - bounding_box_loss: 0.5879 - bounding_box_mae: 0.2659 - bounding_box_mse: 0.1896 - classification_AUC: 0.9844 - classification_f1_score: 0.6398 - classification_loss: 0.0850 - loss: 0.5421 - val_bounding_box_iou_metric: 0.3001 - val_bounding_box_loss: 0.7001 - val_bounding_box_mae: 0.2791 - val_bounding_box_mse: 0.1905 - val_classification_AUC: 0.9088 - val_classification_f1_score: 0.5868 - val_classification_loss: 0.4506 - val_loss: 0.6797 - learning_rate: 1.0000e-05\n",
      "Epoch 82/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4169 - bounding_box_loss: 0.5832 - bounding_box_mae: 0.2636 - bounding_box_mse: 0.1882 - classification_AUC: 0.9823 - classification_f1_score: 0.6337 - classification_loss: 0.0806 - loss: 0.5374\n",
      "Epoch 82: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4169 - bounding_box_loss: 0.5832 - bounding_box_mae: 0.2636 - bounding_box_mse: 0.1882 - classification_AUC: 0.9823 - classification_f1_score: 0.6337 - classification_loss: 0.0805 - loss: 0.5374 - val_bounding_box_iou_metric: 0.3024 - val_bounding_box_loss: 0.6976 - val_bounding_box_mae: 0.2763 - val_bounding_box_mse: 0.1878 - val_classification_AUC: 0.9089 - val_classification_f1_score: 0.5865 - val_classification_loss: 0.4563 - val_loss: 0.6781 - learning_rate: 1.0000e-05\n",
      "Epoch 83/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4255 - bounding_box_loss: 0.5747 - bounding_box_mae: 0.2605 - bounding_box_mse: 0.1848 - classification_AUC: 0.9795 - classification_f1_score: 0.6387 - classification_loss: 0.0742 - loss: 0.5289\n",
      "Epoch 83: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4254 - bounding_box_loss: 0.5747 - bounding_box_mae: 0.2605 - bounding_box_mse: 0.1848 - classification_AUC: 0.9795 - classification_f1_score: 0.6386 - classification_loss: 0.0742 - loss: 0.5289 - val_bounding_box_iou_metric: 0.3033 - val_bounding_box_loss: 0.6966 - val_bounding_box_mae: 0.2798 - val_bounding_box_mse: 0.1914 - val_classification_AUC: 0.9093 - val_classification_f1_score: 0.5904 - val_classification_loss: 0.4559 - val_loss: 0.6771 - learning_rate: 1.0000e-05\n",
      "Epoch 84/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4230 - bounding_box_loss: 0.5771 - bounding_box_mae: 0.2646 - bounding_box_mse: 0.1882 - classification_AUC: 0.9811 - classification_f1_score: 0.6390 - classification_loss: 0.0701 - loss: 0.5305\n",
      "Epoch 84: val_bounding_box_mse did not improve from 0.18616\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4230 - bounding_box_loss: 0.5770 - bounding_box_mae: 0.2646 - bounding_box_mse: 0.1882 - classification_AUC: 0.9811 - classification_f1_score: 0.6390 - classification_loss: 0.0701 - loss: 0.5305 - val_bounding_box_iou_metric: 0.3055 - val_bounding_box_loss: 0.6947 - val_bounding_box_mae: 0.2819 - val_bounding_box_mse: 0.1928 - val_classification_AUC: 0.9086 - val_classification_f1_score: 0.5894 - val_classification_loss: 0.4566 - val_loss: 0.6752 - learning_rate: 1.0000e-05\n",
      "Epoch 85/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - bounding_box_iou_metric: 0.4307 - bounding_box_loss: 0.5693 - bounding_box_mae: 0.2646 - bounding_box_mse: 0.1896 - classification_AUC: 0.9835 - classification_f1_score: 0.6363 - classification_loss: 0.0735 - loss: 0.5238\n",
      "Epoch 85: val_bounding_box_mse improved from 0.18616 to 0.18562, saving model to output/checkpoints/detector_ckpt_85.keras\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 79ms/step - bounding_box_iou_metric: 0.4307 - bounding_box_loss: 0.5693 - bounding_box_mae: 0.2646 - bounding_box_mse: 0.1896 - classification_AUC: 0.9835 - classification_f1_score: 0.6364 - classification_loss: 0.0735 - loss: 0.5238 - val_bounding_box_iou_metric: 0.2947 - val_bounding_box_loss: 0.7054 - val_bounding_box_mae: 0.2766 - val_bounding_box_mse: 0.1856 - val_classification_AUC: 0.9100 - val_classification_f1_score: 0.5906 - val_classification_loss: 0.4547 - val_loss: 0.6845 - learning_rate: 1.0000e-05\n",
      "Epoch 86/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - bounding_box_iou_metric: 0.4309 - bounding_box_loss: 0.5692 - bounding_box_mae: 0.2640 - bounding_box_mse: 0.1889 - classification_AUC: 0.9822 - classification_f1_score: 0.6360 - classification_loss: 0.0767 - loss: 0.5240\n",
      "Epoch 86: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - bounding_box_iou_metric: 0.4309 - bounding_box_loss: 0.5692 - bounding_box_mae: 0.2640 - bounding_box_mse: 0.1889 - classification_AUC: 0.9822 - classification_f1_score: 0.6360 - classification_loss: 0.0766 - loss: 0.5239 - val_bounding_box_iou_metric: 0.3071 - val_bounding_box_loss: 0.6932 - val_bounding_box_mae: 0.2806 - val_bounding_box_mse: 0.1927 - val_classification_AUC: 0.9093 - val_classification_f1_score: 0.5919 - val_classification_loss: 0.4597 - val_loss: 0.6739 - learning_rate: 1.0000e-05\n",
      "Epoch 87/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.4308 - bounding_box_loss: 0.5695 - bounding_box_mae: 0.2637 - bounding_box_mse: 0.1894 - classification_AUC: 0.9806 - classification_f1_score: 0.6407 - classification_loss: 0.0734 - loss: 0.5237\n",
      "Epoch 87: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.4308 - bounding_box_loss: 0.5695 - bounding_box_mae: 0.2637 - bounding_box_mse: 0.1894 - classification_AUC: 0.9807 - classification_f1_score: 0.6407 - classification_loss: 0.0735 - loss: 0.5237 - val_bounding_box_iou_metric: 0.3023 - val_bounding_box_loss: 0.6981 - val_bounding_box_mae: 0.2769 - val_bounding_box_mse: 0.1883 - val_classification_AUC: 0.9096 - val_classification_f1_score: 0.5940 - val_classification_loss: 0.4649 - val_loss: 0.6787 - learning_rate: 1.0000e-05\n",
      "Epoch 88/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.4362 - bounding_box_loss: 0.5641 - bounding_box_mae: 0.2651 - bounding_box_mse: 0.1912 - classification_AUC: 0.9827 - classification_f1_score: 0.6407 - classification_loss: 0.0739 - loss: 0.5188\n",
      "Epoch 88: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.4363 - bounding_box_loss: 0.5640 - bounding_box_mae: 0.2651 - bounding_box_mse: 0.1912 - classification_AUC: 0.9827 - classification_f1_score: 0.6407 - classification_loss: 0.0739 - loss: 0.5188 - val_bounding_box_iou_metric: 0.3039 - val_bounding_box_loss: 0.6964 - val_bounding_box_mae: 0.2786 - val_bounding_box_mse: 0.1893 - val_classification_AUC: 0.9091 - val_classification_f1_score: 0.5930 - val_classification_loss: 0.4666 - val_loss: 0.6772 - learning_rate: 1.0000e-05\n",
      "Epoch 89/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.4392 - bounding_box_loss: 0.5604 - bounding_box_mae: 0.2664 - bounding_box_mse: 0.1935 - classification_AUC: 0.9833 - classification_f1_score: 0.6423 - classification_loss: 0.0680 - loss: 0.5148\n",
      "Epoch 89: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.4393 - bounding_box_loss: 0.5604 - bounding_box_mae: 0.2664 - bounding_box_mse: 0.1934 - classification_AUC: 0.9833 - classification_f1_score: 0.6423 - classification_loss: 0.0680 - loss: 0.5148 - val_bounding_box_iou_metric: 0.3115 - val_bounding_box_loss: 0.6887 - val_bounding_box_mae: 0.2800 - val_bounding_box_mse: 0.1929 - val_classification_AUC: 0.9087 - val_classification_f1_score: 0.5908 - val_classification_loss: 0.4672 - val_loss: 0.6704 - learning_rate: 1.0000e-05\n",
      "Epoch 90/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - bounding_box_iou_metric: 0.4433 - bounding_box_loss: 0.5566 - bounding_box_mae: 0.2637 - bounding_box_mse: 0.1906 - classification_AUC: 0.9855 - classification_f1_score: 0.6447 - classification_loss: 0.0715 - loss: 0.5117\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 90: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step - bounding_box_iou_metric: 0.4433 - bounding_box_loss: 0.5566 - bounding_box_mae: 0.2637 - bounding_box_mse: 0.1906 - classification_AUC: 0.9855 - classification_f1_score: 0.6447 - classification_loss: 0.0715 - loss: 0.5117 - val_bounding_box_iou_metric: 0.3124 - val_bounding_box_loss: 0.6878 - val_bounding_box_mae: 0.2802 - val_bounding_box_mse: 0.1930 - val_classification_AUC: 0.9097 - val_classification_f1_score: 0.5906 - val_classification_loss: 0.4682 - val_loss: 0.6696 - learning_rate: 1.0000e-05\n",
      "Epoch 91/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - bounding_box_iou_metric: 0.4522 - bounding_box_loss: 0.5479 - bounding_box_mae: 0.2644 - bounding_box_mse: 0.1925 - classification_AUC: 0.9823 - classification_f1_score: 0.6385 - classification_loss: 0.0653 - loss: 0.5031\n",
      "Epoch 91: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - bounding_box_iou_metric: 0.4523 - bounding_box_loss: 0.5479 - bounding_box_mae: 0.2644 - bounding_box_mse: 0.1925 - classification_AUC: 0.9823 - classification_f1_score: 0.6385 - classification_loss: 0.0653 - loss: 0.5031 - val_bounding_box_iou_metric: 0.3135 - val_bounding_box_loss: 0.6867 - val_bounding_box_mae: 0.2793 - val_bounding_box_mse: 0.1924 - val_classification_AUC: 0.9093 - val_classification_f1_score: 0.5896 - val_classification_loss: 0.4671 - val_loss: 0.6685 - learning_rate: 1.0000e-06\n",
      "Epoch 92/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - bounding_box_iou_metric: 0.4583 - bounding_box_loss: 0.5417 - bounding_box_mae: 0.2625 - bounding_box_mse: 0.1904 - classification_AUC: 0.9851 - classification_f1_score: 0.6380 - classification_loss: 0.0629 - loss: 0.4973\n",
      "Epoch 92: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - bounding_box_iou_metric: 0.4584 - bounding_box_loss: 0.5416 - bounding_box_mae: 0.2625 - bounding_box_mse: 0.1904 - classification_AUC: 0.9851 - classification_f1_score: 0.6380 - classification_loss: 0.0629 - loss: 0.4973 - val_bounding_box_iou_metric: 0.3136 - val_bounding_box_loss: 0.6867 - val_bounding_box_mae: 0.2786 - val_bounding_box_mse: 0.1917 - val_classification_AUC: 0.9101 - val_classification_f1_score: 0.5905 - val_classification_loss: 0.4640 - val_loss: 0.6681 - learning_rate: 1.0000e-06\n",
      "Epoch 93/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - bounding_box_iou_metric: 0.4704 - bounding_box_loss: 0.5298 - bounding_box_mae: 0.2613 - bounding_box_mse: 0.1914 - classification_AUC: 0.9815 - classification_f1_score: 0.6344 - classification_loss: 0.0772 - loss: 0.4880\n",
      "Epoch 93: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - bounding_box_iou_metric: 0.4704 - bounding_box_loss: 0.5298 - bounding_box_mae: 0.2613 - bounding_box_mse: 0.1914 - classification_AUC: 0.9815 - classification_f1_score: 0.6344 - classification_loss: 0.0771 - loss: 0.4881 - val_bounding_box_iou_metric: 0.3114 - val_bounding_box_loss: 0.6889 - val_bounding_box_mae: 0.2779 - val_bounding_box_mse: 0.1902 - val_classification_AUC: 0.9099 - val_classification_f1_score: 0.5912 - val_classification_loss: 0.4680 - val_loss: 0.6705 - learning_rate: 1.0000e-06\n",
      "Epoch 94/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - bounding_box_iou_metric: 0.4706 - bounding_box_loss: 0.5293 - bounding_box_mae: 0.2596 - bounding_box_mse: 0.1873 - classification_AUC: 0.9831 - classification_f1_score: 0.6414 - classification_loss: 0.0696 - loss: 0.4868\n",
      "Epoch 94: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 74ms/step - bounding_box_iou_metric: 0.4706 - bounding_box_loss: 0.5293 - bounding_box_mae: 0.2596 - bounding_box_mse: 0.1873 - classification_AUC: 0.9831 - classification_f1_score: 0.6414 - classification_loss: 0.0696 - loss: 0.4868 - val_bounding_box_iou_metric: 0.3118 - val_bounding_box_loss: 0.6885 - val_bounding_box_mae: 0.2775 - val_bounding_box_mse: 0.1899 - val_classification_AUC: 0.9099 - val_classification_f1_score: 0.5916 - val_classification_loss: 0.4672 - val_loss: 0.6700 - learning_rate: 1.0000e-06\n",
      "Epoch 95/110\n",
      "\u001b[1m214/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - bounding_box_iou_metric: 0.4714 - bounding_box_loss: 0.5283 - bounding_box_mae: 0.2606 - bounding_box_mse: 0.1873 - classification_AUC: 0.9833 - classification_f1_score: 0.6437 - classification_loss: 0.0700 - loss: 0.4860\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 95: val_bounding_box_mse did not improve from 0.18562\n",
      "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 74ms/step - bounding_box_iou_metric: 0.4714 - bounding_box_loss: 0.5283 - bounding_box_mae: 0.2606 - bounding_box_mse: 0.1874 - classification_AUC: 0.9833 - classification_f1_score: 0.6437 - classification_loss: 0.0700 - loss: 0.4860 - val_bounding_box_iou_metric: 0.3118 - val_bounding_box_loss: 0.6884 - val_bounding_box_mae: 0.2779 - val_bounding_box_mse: 0.1904 - val_classification_AUC: 0.9099 - val_classification_f1_score: 0.5929 - val_classification_loss: 0.4661 - val_loss: 0.6699 - learning_rate: 1.0000e-06\n",
      "Epoch 95: early stopping\n",
      "Restoring model weights from the end of the best epoch: 85.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/24 08:38:14 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during tensorflow autologging: Changing param values is not allowed. Param with key='epochs' was already logged with value='30' for run ID='f0c78cc579984d95a3fb284db4a43dc0'. Attempted logging new value '110'.\n"
     ]
    }
   ],
   "source": [
    "phase3_epoch = phase2_epoch + 40 \n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=phase3_epoch,\n",
    "    initial_epoch=history.epoch[-1],  # Start from the last epoch of initial training\n",
    "    validation_data=valid_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.log_model(\n",
    "model,\n",
    "\"my_model\",\n",
    "signature=signature,\n",
    "code_paths=[\"src/losses\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.tensorflow.log_model(\n",
    "#     model,\n",
    "#     \"my_model\",\n",
    "#     signature=signature,\n",
    "#     code_paths=[\"src/losses\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri: str = \"runs:/{}/model\".format(run.info.run_id)\n",
    "loaded_model = mlflow.tensorflow.load_model(model_uri)\n",
    "\n",
    "loaded_model.evaluate(valid_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Datasets setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_training_results(history):\n",
    "    \"\"\"\n",
    "    Visualizes training and validation loss, and training and validation accuracy.\n",
    "\n",
    "    Args:\n",
    "        history: A dictionary or object containing training history data.\n",
    "                 For example, a Keras History object or a dictionary with keys:\n",
    "                 'loss', 'val_loss', 'accuracy', 'val_accuracy'.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(history, dict):\n",
    "        # Assumes history is a dictionary\n",
    "        loss = history.get('loss')\n",
    "        val_loss = history.get('val_loss')\n",
    "        accuracy = history.get('accuracy')\n",
    "        val_accuracy = history.get('val_accuracy')\n",
    "    else:\n",
    "        # Assumes history is a Keras History object or similar\n",
    "        loss = history.history.get('loss')\n",
    "        val_loss = history.history.get('val_loss')\n",
    "        accuracy = history.history.get('accuracy')\n",
    "        val_accuracy = history.history.get('val_accuracy')\n",
    "\n",
    "    if loss and val_loss:\n",
    "        epochs = range(1, len(loss) + 1)\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Plot training & validation loss values\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "    if accuracy and val_accuracy:\n",
    "        if not (loss and val_loss):\n",
    "          plt.figure(figsize=(12, 5))\n",
    "        else:\n",
    "          plt.subplot(1, 2, 2)\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout() #prevents overlapping titles/labels\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_test_dataset = AnnotationProcessor(annotation_file= str(TEST_DIR/'_annotations.csv'))\n",
    "_class_map = {v: k for k, v in enumerate(CLASS_NAME)}\n",
    "test_image_paths, test_class_ids, test_bboxes = prepare_test_dataset.process_annotations(image_dir=TEST_DIR, class_id_map=_class_map)\n",
    "\n",
    "len(test_image_paths), len(test_class_ids), len(test_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_image_paths, test_class_ids, test_bboxes, img_size=IMG_SIZE)\n",
    "test_ds = test_dl.load_val_dataset()\n",
    "y_true_labels = test_dl.multi_hot_class_ids\n",
    "y_true_bboxes = test_dl.padded_bbx\n",
    "test_ds = Preprocessor(test_ds).preprocess()\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, return_dict=True, steps=1)\n",
    "print(\"Testing accuracy: \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_prob_pred, pred_bbx = model.predict(test_ds)\n",
    "y_prob_pred[0], pred_bbx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_prob_pred>0.5).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true_labels, y_pred, labels=[0,1,2], target_names=CLASS_NAME)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.visualization_funcs import plot_auc_curve\n",
    "\n",
    "\n",
    "plot_auc_curve(OUTPUT_DIR, CLASS_NAME, y_true_labels, y_prob_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bbx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.losses.iou_loss import iou_metric\n",
    "def plot_iou_histogram(y_true_bbox, y_pred_bbox, class_ids):\n",
    "    \"\"\"\n",
    "    Plots a histogram of Intersection over Union (IoU) scores.\n",
    "\n",
    "    Args:\n",
    "        y_true_bbox: Ground truth bounding boxes (list of lists or numpy array).\n",
    "        y_pred_bbox: Predicted bounding boxes (list of lists or numpy array).\n",
    "        class_ids: list of class ids.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1)\n",
    "\n",
    "    iou_scores = iou_metric(y_true_bbox, y_pred_bbox)\n",
    "\n",
    "    # fig.figure(figsize=(10, 6))\n",
    "    axs.hist(iou_scores, bins=20, range=(0, 1), edgecolor='black')\n",
    "    axs.set_title('IoU Score Distribution')\n",
    "    axs.set_xlabel('IoU Score')\n",
    "    axs.set_ylabel('Frequency')\n",
    "    axs.grid(True)\n",
    "    plt.show()\n",
    "    plt.savefig(f\"{OUTPUT_DIR}/iou_histogram.png\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_iou_histogram(y_true_bboxes, pred_bbx, pred_bbx)\n",
    "mlflow.log_figure(fig, 'iou_histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
