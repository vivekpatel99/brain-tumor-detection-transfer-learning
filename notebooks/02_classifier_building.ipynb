{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection\n",
    "## Single Task Validation - Building multi-lable binary Classifier\n",
    "Description\n",
    "This dataset was originally created by Yousef Ghanem. To see the current project, which may have been updated since this version, please go here: https://universe.roboflow.com/yousef-ghanem-jzj4y/brain-tumor-detection-fpf1f.\n",
    "\n",
    "This dataset is part of RF100, an Intel-sponsored initiative to create a new object detection benchmark for model generalizability.\n",
    "\n",
    "Access the RF100 Github repo: https://github.com/roboflow-ai/roboflow-100-benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/brain-tumor-detection'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go to project root folder\n",
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 10:40:24.739758: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741862424.747632  167540 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741862424.750948  167540 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1741862424.761803  167540 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1741862424.761831  167540 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1741862424.761834  167540 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1741862424.761836  167540 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-13 10:40:24.765603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')], '2.19.0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_gpu = tf.config.list_physical_devices('GPU')\n",
    "if not found_gpu:\n",
    "    raise Exception(\"No GPU found\")\n",
    "found_gpu, tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_handler.data_loader import DataLoader\n",
    "from src.data_handler.annotation_processor import AnnotationProcessor\n",
    "from src.data_handler.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload dotenv \n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# auto reload libs\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/brain-tumor-2/train/\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "# https://gist.github.com/bdsaglam/586704a98336a0cf0a65a6e7c247d248\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../conf\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    print(cfg.DATASET_DIRS.TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/train/', 'VALIDATION_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/valid', 'TEST_DIR': '${DATASET.DATASET_DIR}/${DATASET.DATASET_NAME}/test'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.DATASET_DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRS = Path(cfg.DATASET.DATASET_DIR)\n",
    "TRAIN_DIR = Path(cfg.DATASET_DIRS.TRAIN_DIR)\n",
    "VALIDATION_DIR = Path(cfg.DATASET_DIRS.VALIDATION_DIR)\n",
    "TEST_DIR = Path(cfg.DATASET_DIRS.TEST_DIR)\n",
    "\n",
    "\n",
    "IMG_SIZE = cfg.TRAIN.IMG_SIZE\n",
    "BATCH_SIZE = cfg.TRAIN.BATCH_SIZE\n",
    "LOG_DIR = cfg.OUTPUTS.LOG_DIR\n",
    "CHECK_POINT_DIR = Path(cfg.OUTPUTS.CHECKPOINT_PATH)\n",
    "CLASS_NAME = [\n",
    "    'label0',\n",
    "    'label1',\n",
    "    'label2'\n",
    "]\n",
    "class_map = {k: v for k, v in enumerate(CLASS_NAME)}\n",
    "\n",
    "NUM_EPOCHS = cfg.TRAIN.NUM_EPOCHS\n",
    "LEARNING_RATE = cfg.TRAIN.LEARNING_RATE\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAIN_DIR.exists():\n",
    "    from roboflow import Roboflow\n",
    "    rf = Roboflow()\n",
    "    project = rf.workspace(\"roboflow-100\").project(\"brain-tumor-m2pbp\")\n",
    "    version = project.version(2)\n",
    "    dataset = version.download(\"tensorflow\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images from directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6930, 6930, 6930)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_train_dataset = AnnotationProcessor(annotation_file= str(TRAIN_DIR/'_annotations.csv'))\n",
    "_class_map = {v: k for k, v in enumerate(CLASS_NAME)}\n",
    "train_images, train_class_ids, train_bboxes  = prepare_train_dataset.process_annotations(image_dir=TRAIN_DIR, class_id_map=_class_map)\n",
    "\n",
    "len(train_images), len(train_class_ids), len(train_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('datasets/brain-tumor-2/train/volume_337_slice_89_jpg.rf.63cc21fc850bfb89383c90a49ece9826.jpg',\n",
       " [0, 1, 2],\n",
       " array([[0.57916667, 0.33333333, 0.75833333, 0.425     ],\n",
       "        [0.5375    , 0.275     , 0.82916667, 0.5125    ],\n",
       "        [0.57083333, 0.32083333, 0.76666667, 0.45416667]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0],train_class_ids[0], train_bboxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741862438.866017  167540 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7183 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_images, train_class_ids, train_bboxes)\n",
    "train_ds = train_dl.load_train_dataset()\n",
    "train_ds = Preprocessor(train_ds).preprocess()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n",
      "(32, 240, 240, 3)\n",
      "-122.40152 150.3729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 10:40:44.858006: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in train_ds.take(1):\n",
    "    image, cls = batch\n",
    "    print(cls.shape)\n",
    "    print(image.shape)\n",
    "    print(image[1].numpy().min(), image[1].numpy().max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980, 1980, 1980)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_valid_dataset = AnnotationProcessor(annotation_file= str(VALIDATION_DIR/'_annotations.csv'))\n",
    "\n",
    "valid_image_paths, valid_class_ids, valid_bboxes  = prepare_valid_dataset.process_annotations(image_dir=VALIDATION_DIR, class_id_map=_class_map)\n",
    "len(valid_image_paths), len(valid_class_ids), len(valid_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_image_paths, valid_class_ids, valid_bboxes).load_val_dataset()\n",
    "valid_ds = Preprocessor(valid_dl).preprocess()\n",
    "valid_ds = valid_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n",
      "(32, 240, 240, 3)\n",
      "-123.68 147.061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 10:40:46.285526: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in valid_ds.take(1):\n",
    "    image, cls, = batch\n",
    "    print(cls.shape)\n",
    "    print(image.shape)\n",
    "    print(image[1].numpy().min(), image[1].numpy().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC', multi_label=True), \n",
    "    tf.keras.metrics.F1Score(name='f1_score',average='weighted'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define  Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "to_monitor = 'val_loss'\n",
    "mode = 'min'\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, \n",
    "                                            patience=2, \n",
    "                                            monitor=to_monitor,\n",
    "                                            mode=mode,\n",
    "                                            min_lr=1e-6,\n",
    "                                            verbose=1),\n",
    "\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(str(CHECK_POINT_DIR), \"classifier_ckpt_{epoch}.keras\") ,\n",
    "                                        save_weights_only=False,\n",
    "                                        save_best_only=True,\n",
    "                                        monitor=to_monitor,\n",
    "                                        mode=mode,\n",
    "                                        verbose=1),\n",
    "                                        \n",
    "    tf.keras.callbacks.EarlyStopping(monitor=to_monitor, \n",
    "                                    patience=10,\n",
    "                                    mode=mode, \n",
    "                                    restore_best_weights=True),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.62597403, 0.31861472, 0.47417027]),\n",
       " array([0.37633478, 0.74805195, 1.05165945]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.losses import binary_weighted_loss as _loss\n",
    "padded_class_ids, _ = train_dl.pad_cls_id_bbx()\n",
    "\n",
    "positive_weights, negative_weights = _loss.compute_class_weights(padded_class_ids)\n",
    "positive_weights, negative_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_proportions = np.array([0.28360356, 0.44691423, 0.26948222])\n",
    "total_samples = len(train_images)  # Or the actual total if you have it\n",
    "class_weights = 1 / class_proportions\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ResNet50 Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.resnet50 import resnet50_classifier\n",
    "tf.keras.backend.clear_session()\n",
    "model = resnet50_classifier(input_shape=(IMG_SIZE,IMG_SIZE,3), num_classes=NUM_CLASSES)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    # loss= tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    loss= _loss.set_binary_crossentropy_weighted_loss(positive_weights, negative_weights),\n",
    "    metrics=METRICS)  # Use IoU metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"/brain-tumor-resnet50_classifier\")\n",
    "mlflow.tensorflow.autolog(log_models=True, log_datasets=False)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    # class_weight=class_weight_dict,\n",
    "    callbacks=[callbacks],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_training_results(history):\n",
    "    \"\"\"\n",
    "    Visualizes training and validation loss, and training and validation accuracy.\n",
    "\n",
    "    Args:\n",
    "        history: A dictionary or object containing training history data.\n",
    "                 For example, a Keras History object or a dictionary with keys:\n",
    "                 'loss', 'val_loss', 'accuracy', 'val_accuracy'.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(history, dict):\n",
    "        # Assumes history is a dictionary\n",
    "        loss = history.get('loss')\n",
    "        val_loss = history.get('val_loss')\n",
    "        accuracy = history.get('accuracy')\n",
    "        val_accuracy = history.get('val_accuracy')\n",
    "    else:\n",
    "        # Assumes history is a Keras History object or similar\n",
    "        loss = history.history.get('loss')\n",
    "        val_loss = history.history.get('val_loss')\n",
    "        accuracy = history.history.get('accuracy')\n",
    "        val_accuracy = history.history.get('val_accuracy')\n",
    "\n",
    "    if loss and val_loss:\n",
    "        epochs = range(1, len(loss) + 1)\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Plot training & validation loss values\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "        plt.title('Training and validation loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "    if accuracy and val_accuracy:\n",
    "        if not (loss and val_loss):\n",
    "          plt.figure(figsize=(12, 5))\n",
    "        else:\n",
    "          plt.subplot(1, 2, 2)\n",
    "        # Plot training & validation accuracy values\n",
    "        plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "        plt.title('Training and validation accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout() #prevents overlapping titles/labels\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Datasets setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prepare_test_dataset = AnnotationProcessor(annotation_file= str(TEST_DIR/'_annotations.csv'))\n",
    "_class_map = {v: k for k, v in enumerate(CLASS_NAME)}\n",
    "test_image_paths, test_class_ids, test_bboxes = prepare_test_dataset.process_annotations(image_dir=TEST_DIR, class_id_map=_class_map)\n",
    "\n",
    "len(test_image_paths), len(test_class_ids), len(test_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_image_paths, test_class_ids, test_bboxes).load_val_dataset()\n",
    "test_ds = Preprocessor(test_dl).preprocess()\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\\\n",
    "                .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds, return_dict=True, steps=1)\n",
    "print(\"Testing accuracy: \", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_true = test_class_ids\n",
    "y_pred = model.predict(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true_bin = mlb.fit_transform(y_true)\n",
    "y_pred_bin = mlb.transform(y_pred) #use transform, not fit_transform\n",
    "y_true_bin,y_pred_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_bin, y_pred_bin, labels=[0,1,2], target_names=CLASS_NAME))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
